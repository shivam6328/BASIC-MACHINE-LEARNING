{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Command line args are ['/home/shivam/.local/lib/python2.7/site-packages/ipykernel_launcher.py', '-f', '/home/shivam/.local/share/jupyter/runtime/kernel-34267f86-4422-45f3-894b-ca95d823b624.json']: \n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-66e5ac0545b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-66e5ac0545b8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Command line args are {}: \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_csv_to_header_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'data_file'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-66e5ac0545b8>\u001b[0m in \u001b[0;36mload_config\u001b[0;34m(config_file)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mast\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mliteral_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '-f'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import csv\n",
    "import sys\n",
    "import math\n",
    "import os\n",
    "\n",
    "\n",
    "def load_csv_to_header_data(filename):\n",
    "    fpath = os.path.join(os.getcwd(), filename)\n",
    "    fs = csv.reader(open(fpath, newline='\\n'))\n",
    "\n",
    "    all_row = []\n",
    "    for r in fs:\n",
    "        all_row.append(r)\n",
    "\n",
    "    headers = all_row[0]\n",
    "    idx_to_name, name_to_idx = get_header_name_to_idx_maps(headers)\n",
    "\n",
    "    data = {\n",
    "        'header': headers,\n",
    "        'rows': all_row[1:],\n",
    "        'name_to_idx': name_to_idx,\n",
    "        'idx_to_name': idx_to_name\n",
    "    }\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_header_name_to_idx_maps(headers):\n",
    "    name_to_idx = {}\n",
    "    idx_to_name = {}\n",
    "    for i in range(0, len(headers)):\n",
    "        name_to_idx[headers[i]] = i\n",
    "        idx_to_name[i] = headers[i]\n",
    "    return idx_to_name, name_to_idx\n",
    "\n",
    "\n",
    "def project_columns(data, columns_to_project):\n",
    "    data_h = list(data['header'])\n",
    "    data_r = list(data['rows'])\n",
    "\n",
    "    all_cols = list(range(0, len(data_h)))\n",
    "\n",
    "    columns_to_project_ix = [data['name_to_idx'][name] for name in columns_to_project]\n",
    "    columns_to_remove = [cidx for cidx in all_cols if cidx not in columns_to_project_ix]\n",
    "\n",
    "    for delc in sorted(columns_to_remove, reverse=True):\n",
    "        del data_h[delc]\n",
    "        for r in data_r:\n",
    "            del r[delc]\n",
    "\n",
    "    idx_to_name, name_to_idx = get_header_name_to_idx_maps(data_h)\n",
    "\n",
    "    return {'header': data_h, 'rows': data_r,\n",
    "            'name_to_idx': name_to_idx,\n",
    "            'idx_to_name': idx_to_name}\n",
    "\n",
    "\n",
    "def get_uniq_values(data):\n",
    "    idx_to_name = data['idx_to_name']\n",
    "    idxs = idx_to_name.keys()\n",
    "\n",
    "    val_map = {}\n",
    "    for idx in iter(idxs):\n",
    "        val_map[idx_to_name[idx]] = set()\n",
    "\n",
    "    for data_row in data['rows']:\n",
    "        for idx in idx_to_name.keys():\n",
    "            att_name = idx_to_name[idx]\n",
    "            val = data_row[idx]\n",
    "            if val not in val_map.keys():\n",
    "                val_map[att_name].add(val)\n",
    "    return val_map\n",
    "\n",
    "\n",
    "def get_class_labels(data, target_attribute):\n",
    "    rows = data['rows']\n",
    "    col_idx = data['name_to_idx'][target_attribute]\n",
    "    labels = {}\n",
    "    for r in rows:\n",
    "        val = r[col_idx]\n",
    "        if val in labels:\n",
    "            labels[val] = labels[val] + 1\n",
    "        else:\n",
    "            labels[val] = 1\n",
    "    return labels\n",
    "\n",
    "\n",
    "def entropy(n, labels):\n",
    "    ent = 0\n",
    "    for label in labels.keys():\n",
    "        p_x = labels[label] / n\n",
    "        ent += - p_x * math.log(p_x, 2)\n",
    "    return ent\n",
    "\n",
    "\n",
    "def partition_data(data, group_att):\n",
    "    partitions = {}\n",
    "    data_rows = data['rows']\n",
    "    partition_att_idx = data['name_to_idx'][group_att]\n",
    "    for row in data_rows:\n",
    "        row_val = row[partition_att_idx]\n",
    "        if row_val not in partitions.keys():\n",
    "            partitions[row_val] = {\n",
    "                'name_to_idx': data['name_to_idx'],\n",
    "                'idx_to_name': data['idx_to_name'],\n",
    "                'rows': list()\n",
    "            }\n",
    "        partitions[row_val]['rows'].append(row)\n",
    "    return partitions\n",
    "\n",
    "\n",
    "def avg_entropy_w_partitions(data, splitting_att, target_attribute):\n",
    "    # find uniq values of splitting att\n",
    "    data_rows = data['rows']\n",
    "    n = len(data_rows)\n",
    "    partitions = partition_data(data, splitting_att)\n",
    "\n",
    "    avg_ent = 0\n",
    "\n",
    "    for partition_key in partitions.keys():\n",
    "        partitioned_data = partitions[partition_key]\n",
    "        partition_n = len(partitioned_data['rows'])\n",
    "        partition_labels = get_class_labels(partitioned_data, target_attribute)\n",
    "        partition_entropy = entropy(partition_n, partition_labels)\n",
    "        avg_ent += partition_n / n * partition_entropy\n",
    "\n",
    "    return avg_ent, partitions\n",
    "\n",
    "\n",
    "def most_common_label(labels):\n",
    "    mcl = max(labels, key=lambda k: labels[k])\n",
    "    return mcl\n",
    "\n",
    "\n",
    "def id3(data, uniqs, remaining_atts, target_attribute):\n",
    "    labels = get_class_labels(data, target_attribute)\n",
    "\n",
    "    node = {}\n",
    "\n",
    "    if len(labels.keys()) == 1:\n",
    "        node['label'] = next(iter(labels.keys()))\n",
    "        return node\n",
    "\n",
    "    if len(remaining_atts) == 0:\n",
    "        node['label'] = most_common_label(labels)\n",
    "        return node\n",
    "\n",
    "    n = len(data['rows'])\n",
    "    ent = entropy(n, labels)\n",
    "\n",
    "    max_info_gain = None\n",
    "    max_info_gain_att = None\n",
    "    max_info_gain_partitions = None\n",
    "\n",
    "    for remaining_att in remaining_atts:\n",
    "        avg_ent, partitions = avg_entropy_w_partitions(data, remaining_att, target_attribute)\n",
    "        info_gain = ent - avg_ent\n",
    "        if max_info_gain is None or info_gain > max_info_gain:\n",
    "            max_info_gain = info_gain\n",
    "            max_info_gain_att = remaining_att\n",
    "            max_info_gain_partitions = partitions\n",
    "\n",
    "    if max_info_gain is None:\n",
    "        node['label'] = most_common_label(labels)\n",
    "        return node\n",
    "\n",
    "    node['attribute'] = max_info_gain_att\n",
    "    node['nodes'] = {}\n",
    "\n",
    "    remaining_atts_for_subtrees = set(remaining_atts)\n",
    "    remaining_atts_for_subtrees.discard(max_info_gain_att)\n",
    "\n",
    "    uniq_att_values = uniqs[max_info_gain_att]\n",
    "\n",
    "    for att_value in uniq_att_values:\n",
    "        if att_value not in max_info_gain_partitions.keys():\n",
    "            node['nodes'][att_value] = {'label': most_common_label(labels)}\n",
    "            continue\n",
    "        partition = max_info_gain_partitions[att_value]\n",
    "        node['nodes'][att_value] = id3(partition, uniqs, remaining_atts_for_subtrees, target_attribute)\n",
    "\n",
    "    return node\n",
    "\n",
    "\n",
    "def load_config(config_file):\n",
    "    with open(config_file, 'r') as myfile:\n",
    "        data = myfile.read().replace('\\n', '')\n",
    "    return ast.literal_eval(data)\n",
    "\n",
    "\n",
    "def pretty_print_tree(root):\n",
    "    stack = []\n",
    "    rules = set()\n",
    "\n",
    "    def traverse(node, stack, rules):\n",
    "        if 'label' in node:\n",
    "            stack.append(' THEN ' + node['label'])\n",
    "            rules.add(''.join(stack))\n",
    "            stack.pop()\n",
    "        elif 'attribute' in node:\n",
    "            ifnd = 'IF ' if not stack else ' AND '\n",
    "            stack.append(ifnd + node['attribute'] + ' EQUALS ')\n",
    "            for subnode_key in node['nodes']:\n",
    "                stack.append(subnode_key)\n",
    "                traverse(node['nodes'][subnode_key], stack, rules)\n",
    "                stack.pop()\n",
    "            stack.pop()\n",
    "\n",
    "    traverse(root, stack, rules)\n",
    "    print(os.linesep.join(rules))\n",
    "\n",
    "\n",
    "def main():\n",
    "    argv = sys.argv\n",
    "    print(\"Command line args are {}: \".format(argv))\n",
    "\n",
    "    config = load_config(argv[1])\n",
    "\n",
    "    data = load_csv_to_header_data(config['data_file'])\n",
    "    data = project_columns(data, config['data_project_columns'])\n",
    "\n",
    "    target_attribute = config['target_attribute']\n",
    "    remaining_attributes = set(data['header'])\n",
    "    remaining_attributes.remove(target_attribute)\n",
    "\n",
    "    uniqs = get_uniq_values(data)\n",
    "\n",
    "    root = id3(data, uniqs, remaining_attributes, target_attribute)\n",
    "\n",
    "    pretty_print_tree(root)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\": main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
